{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TileDB VCF Example for 1000 Genomes Project\n",
    "\n",
    "This tutorial provides a walkthrough of [TileDB-VCF](https://github.com/TileDB-Inc/TileDB-VCF.git) using Phase 3 data produced by the [1000 Genomes Project](https://www.internationalgenome.org/). The goal is to highlight storing these samples in TileDB-VCF along with querying in python and exporting back to VCF and TSV.\n",
    "\n",
    "Please see the [official documentation](https://docs.tiledb.com/solutions/integrations/population-genomics) for more comprehensive usage details, API references, as well as instructions for installing TileDB-VCF.\n",
    "\n",
    "## Preprocessing the Raw 1KG pVCF File\n",
    "\n",
    "*Note: We're only working with data from chromosome 1 for the purposes of this tutorial. However, the process of working with whole genome data is the same.*\n",
    "\n",
    "The original VCF file was downloaded from the AWS Open Data Registry: <a href=\"https://registry.opendata.aws/1000-genomes\" class=\"uri\">https://registry.opendata.aws/1000-genomes</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://1000genomes/release/20130502/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz to data/1000genomes/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync \\\n",
    "    --exclude \"*\" --include \"ALL.chr.*\" \\\n",
    "    s3://1000genomes/release/20130502/ \\\n",
    "    data/1000genomes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the more modern high-coverage version of the thousand genomes (1KG) data, which provides the raw single-sample gVCF files TileDB-VCF was designed for, the low-coverage Phase 3 data provides only cohort-level project VCF (pVCF) files for each contig. Therefore, we must first split the pVCF file back into single-sample VCF files prior to ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools +split \\\n",
    "    -Ob \\\n",
    "    -o data/split-bcfs \\\n",
    "    data/1000genomes/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we’ll filter the split VCF files to include only records with a non-reference allele and remove `INFO` attributes that are either static (e.g., `NS`) or cohort-specific and recoverable (e.g., `AF`). We’ll save the final pre-processed files in *BCF* format, which is a binary representation of the VCF format. The resulting filtered BCF files are a close approximation of the raw single sample VCF files typically stored for large population genomics projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm_tags=INFO/AF,INFO/NS,INFO/EAS_AF,INFO/AMR_AF,INFO/AFR_AF,INFO/EUR_AF,INFO/SAS_AF\n",
    "\n",
    "!ls data/split-bcfs/*.bcf | parallel -j16 \\\n",
    "    \"bcftools view --min-ac 1 -Ou -s {/.} {} | bcftools annotate -Ob --remove $rm_tags -o data/filtered-bcfs/{/}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new BCF files must also be indexed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/filtered-bcfs/*.bcf | parallel -j16 \"bcftools index {}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we’ll store these pre-processed files on S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive data/filtered-bcfs/ s3://genomic-datasets/notebooks/1kgp3/filtered-bcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data in TileDB VCF\n",
    "\n",
    "Next we will create a TileDB VCF dataset and ingest the VCF data.\n",
    "\n",
    "The following was run on a `m5.4xlarge` system with a 300GB EBS volume to handle the large number of VCF files. Note that TileDB is *highly-tunable* and while the defaults were chosen to provide a good balance between ingestion speed, read performance, and dataset size, they can be be tweaked to better suit a specific use case.\n",
    "\n",
    "### Create the dataset\n",
    "\n",
    "You can create a TileDB VCF dataset anywhere that TileDB supports, this could be a local filesystem, s3, azure, gcs, hdfs, and more. For this example we’ll create it on s3, the most common use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'envbash'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ad7ab9f8d7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtiledbvcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menvbash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_envbash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtiledbvcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'envbash'"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import tiledbvcf\n",
    "from envbash import load_envbash\n",
    "\n",
    "tiledbvcf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "aws_bucket=\"genomic-datasets\"\n",
    "array_prefix=\"1kg/1kgdbv5\"\n",
    "array_uri = f\"s3://{aws_bucket}/{array_prefix}\"\n",
    "\n",
    "bcfs_prefix=\"1kg/1kgdbv5_supp\"\n",
    "bcf_uris = []\n",
    "\n",
    "bedfile = \"s3://genomic-datasets/notebooks/1kgp3/hg37_chr1_covidHgiGwasR4PvalC2_plog3.bed.gz\""
   ]
  },
  {
   "source": [
    "Create a list of S3 URIs for the preprocessed BCF files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Retrieved 1000 records\n",
      "Retrieved 1000 records\n",
      "Retrieved 1000 records\n",
      "Retrieved 1000 records\n",
      "Retrieved 1000 records\n",
      "Retrieved 8 records\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "response = s3.list_objects_v2(Bucket=aws_bucket, Prefix=bcfs_prefix)\n",
    "response_files = response[\"Contents\"]\n",
    "list_incomplete = response[\"IsTruncated\"]\n",
    "print(f\"Retrieved {response['KeyCount']} records\")\n",
    "\n",
    "while list_incomplete:\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=aws_bucket, \n",
    "        Prefix=bcfs_prefix,\n",
    "        ContinuationToken = response[\"NextContinuationToken\"]\n",
    "    )\n",
    "    print(f\"Retrieved {response['KeyCount']} records\")\n",
    "    response_files.extend(response[\"Contents\"])\n",
    "    list_incomplete = response[\"IsTruncated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identified 2504 BCF files\n"
     ]
    }
   ],
   "source": [
    "bcf_uris = []\n",
    "for file in response_files:\n",
    "    if \"csi\" in file[\"Key\"]:\n",
    "        next\n",
    "    else:\n",
    "        bcf_uris.append(f\"s3://{aws_bucket}/{file['Key']}\")\n",
    "print(f\"Identified {len(bcf_uris)} BCF files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tiledbvcf.dataset.Dataset at 0x7fb72eafd290>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "ds = tiledbvcf.Dataset(array_uri, stats = True, verbose = True, mode = \"w\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create_dataset(extra_attrs = [\"fmt_GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ingest_samples(\n",
    "    sample_uris = bcf_uris,\n",
    "    threads = 12,\n",
    "    memory_budget_mb = 2048 * 4,\n",
    "    record_limit = 100000,\n",
    "    sample_batch_size = 20,\n",
    "    scratch_space_path = \"/mnt/data/tmp\",\n",
    "    scratch_space_size = 1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n==== WRITE ====\n\n- Number of write queries: 22050\n\n- Number of attributes written: 198450\n  * Number of fixed-sized attributes written: 66150\n  * Number of var-sized attributes written: 132300\n- Number of dimensions written: 66150\n  * Number of fixed-sized dimensions written: 22050\n  * Number of var-sized dimensions written: 44100\n\n- Number of bytes written: 23400433890 bytes (21.7934 GB) \n- Number of write operations: 6772410\n- Number of bytes filtered: 707700421567 bytes (659.097 GB) \n- Filtering deflation factor: 30.243x\n\n- Total metadata written: 23692512 bytes (0.0220654 GB) \n  * Array schema: 813 bytes (7.57165e-07 GB) \n  * Fragment metadata footer: 279972 bytes (0.000260744 GB) \n  * R-tree: 2097900 bytes (0.00195382 GB) \n  * Fixed-sized tile offsets: 10494727 bytes (0.00977398 GB) \n  * Var-sized tile offsets: 7519301 bytes (0.00700289 GB) \n  * Var-sized tile sizes: 3299799 bytes (0.00307318 GB) \n\n- Time to write array metadata: 0.372803 secs\n  * Array metadata size: 110 bytes (1.02445e-07 GB) \n\n- Number of logical cells written: 3364710818\n- Number of logical tiles written: 336726\n  * Number of fixed-sized physical tiles written: 29699233200\n  * Number of var-sized physical tiles written: 118796932800\n\n- Write time: 1932.56 secs\n  * Time to split the coordinates buffer: 0.014829 secs\n  * Time to check out-of-bounds coordinates: 22.3323 secs\n  * Time to check coordinate duplicates: 0.0150717 secs\n  * Time to check global order: 50.2057 secs\n  * Time to prepare tiles: 689.724 secs\n  * Time to compute coordinate metadata (e.g., MBRs): 87.1219 secs\n  * Time to filter tiles: 873.467 secs\n  * Time to write tiles: 207.986 secs\n  * Time to write fragment metadata: 366 secs\n\n- Time to finalize write query: 3671.25 secs\n\n\n\n"
     ]
    }
   ],
   "source": [
    "print(ds.tiledb_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tiledbvcf.dataset.Dataset at 0x7fbaaaa483d0>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "ds = tiledbvcf.Dataset(uri, stats = True, verbose = True, mode = \"r\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the data\n",
    "\n",
    "To store the VCF data in TileDB VCF you simply need a list of the VCF/BCF file locations (e.g., local file paths, S3 URIs, *etc*).\n",
    "\n",
    "Run the following command to ingest the pre-processed BCF files into the TileDB-VCF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['HG00096',\n",
       " 'HG00097',\n",
       " 'HG00099',\n",
       " 'HG00100',\n",
       " 'HG00101',\n",
       " 'HG00102',\n",
       " 'HG00103',\n",
       " 'HG00105',\n",
       " 'HG00106',\n",
       " 'HG00107',\n",
       " 'HG00108',\n",
       " 'HG00109',\n",
       " 'HG00110',\n",
       " 'HG00111',\n",
       " 'HG00112',\n",
       " 'HG00113',\n",
       " 'HG00114',\n",
       " 'HG00115',\n",
       " 'HG00116',\n",
       " 'HG00117',\n",
       " 'HG00118',\n",
       " 'HG00119',\n",
       " 'HG00120',\n",
       " 'HG00121',\n",
       " 'HG00122',\n",
       " 'HG00123',\n",
       " 'HG00125',\n",
       " 'HG00126',\n",
       " 'HG00127',\n",
       " 'HG00128',\n",
       " 'HG00129',\n",
       " 'HG00130',\n",
       " 'HG00131',\n",
       " 'HG00132',\n",
       " 'HG00133',\n",
       " 'HG00136',\n",
       " 'HG00137',\n",
       " 'HG00138',\n",
       " 'HG00139',\n",
       " 'HG00140',\n",
       " 'HG00141',\n",
       " 'HG00142',\n",
       " 'HG00143',\n",
       " 'HG00145',\n",
       " 'HG00146',\n",
       " 'HG00148',\n",
       " 'HG00149',\n",
       " 'HG00150',\n",
       " 'HG00151',\n",
       " 'HG00154',\n",
       " 'HG00155',\n",
       " 'HG00157',\n",
       " 'HG00158',\n",
       " 'HG00159',\n",
       " 'HG00160',\n",
       " 'HG00171',\n",
       " 'HG00173',\n",
       " 'HG00174',\n",
       " 'HG00176',\n",
       " 'HG00177',\n",
       " 'HG00178',\n",
       " 'HG00179',\n",
       " 'HG00180',\n",
       " 'HG00181',\n",
       " 'HG00182',\n",
       " 'HG00183',\n",
       " 'HG00185',\n",
       " 'HG00186',\n",
       " 'HG00187',\n",
       " 'HG00188',\n",
       " 'HG00189',\n",
       " 'HG00190',\n",
       " 'HG00231',\n",
       " 'HG00232',\n",
       " 'HG00233',\n",
       " 'HG00234',\n",
       " 'HG00235',\n",
       " 'HG00236',\n",
       " 'HG00237',\n",
       " 'HG00238',\n",
       " 'HG00239',\n",
       " 'HG00240',\n",
       " 'HG00242',\n",
       " 'HG00243',\n",
       " 'HG00244',\n",
       " 'HG00245',\n",
       " 'HG00246',\n",
       " 'HG00250',\n",
       " 'HG00251',\n",
       " 'HG00252',\n",
       " 'HG00253',\n",
       " 'HG00254',\n",
       " 'HG00255',\n",
       " 'HG00256',\n",
       " 'HG00257',\n",
       " 'HG00258',\n",
       " 'HG00259',\n",
       " 'HG00260',\n",
       " 'HG00261',\n",
       " 'HG00262',\n",
       " 'HG00263',\n",
       " 'HG00264',\n",
       " 'HG00265',\n",
       " 'HG00266',\n",
       " 'HG00267',\n",
       " 'HG00268',\n",
       " 'HG00269',\n",
       " 'HG00271',\n",
       " 'HG00272',\n",
       " 'HG00273',\n",
       " 'HG00274',\n",
       " 'HG00275',\n",
       " 'HG00276',\n",
       " 'HG00277',\n",
       " 'HG00278',\n",
       " 'HG00280',\n",
       " 'HG00281',\n",
       " 'HG00282',\n",
       " 'HG00284',\n",
       " 'HG00285',\n",
       " 'HG00288',\n",
       " 'HG00290',\n",
       " 'HG00304',\n",
       " 'HG00306',\n",
       " 'HG00308',\n",
       " 'HG00309',\n",
       " 'HG00310',\n",
       " 'HG00311',\n",
       " 'HG00313',\n",
       " 'HG00315',\n",
       " 'HG00318',\n",
       " 'HG00319',\n",
       " 'HG00320',\n",
       " 'HG00321',\n",
       " 'HG00323',\n",
       " 'HG00324',\n",
       " 'HG00325',\n",
       " 'HG00326',\n",
       " 'HG00327',\n",
       " 'HG00328',\n",
       " 'HG00329',\n",
       " 'HG00330',\n",
       " 'HG00331',\n",
       " 'HG00332',\n",
       " 'HG00334',\n",
       " 'HG00335',\n",
       " 'HG00336',\n",
       " 'HG00337',\n",
       " 'HG00338',\n",
       " 'HG00339',\n",
       " 'HG00341',\n",
       " 'HG00342',\n",
       " 'HG00343',\n",
       " 'HG00344',\n",
       " 'HG00345',\n",
       " 'HG00346',\n",
       " 'HG00349',\n",
       " 'HG00350',\n",
       " 'HG00351',\n",
       " 'HG00353',\n",
       " 'HG00355',\n",
       " 'HG00356',\n",
       " 'HG00357',\n",
       " 'HG00358',\n",
       " 'HG00360',\n",
       " 'HG00361',\n",
       " 'HG00362',\n",
       " 'HG00364',\n",
       " 'HG00365',\n",
       " 'HG00366',\n",
       " 'HG00367',\n",
       " 'HG00368',\n",
       " 'HG00369',\n",
       " 'HG00371',\n",
       " 'HG00372',\n",
       " 'HG00373',\n",
       " 'HG00375',\n",
       " 'HG00376',\n",
       " 'HG00378',\n",
       " 'HG00379',\n",
       " 'HG00380',\n",
       " 'HG00381',\n",
       " 'HG00382',\n",
       " 'HG00383',\n",
       " 'HG00384',\n",
       " 'HG00403',\n",
       " 'HG00404',\n",
       " 'HG00406',\n",
       " 'HG00407',\n",
       " 'HG00409',\n",
       " 'HG00410',\n",
       " 'HG00419',\n",
       " 'HG00421',\n",
       " 'HG00422',\n",
       " 'HG00428',\n",
       " 'HG00436',\n",
       " 'HG00437',\n",
       " 'HG00442',\n",
       " 'HG00443',\n",
       " 'HG00445',\n",
       " 'HG00446',\n",
       " 'HG00448',\n",
       " 'HG00449',\n",
       " 'HG00451',\n",
       " 'HG00452',\n",
       " 'HG00457',\n",
       " 'HG00458',\n",
       " 'HG00463',\n",
       " 'HG00464',\n",
       " 'HG00472',\n",
       " 'HG00473',\n",
       " 'HG00475',\n",
       " 'HG00476',\n",
       " 'HG00478',\n",
       " 'HG00479',\n",
       " 'HG00500',\n",
       " 'HG00513',\n",
       " 'HG00524',\n",
       " 'HG00525',\n",
       " 'HG00530',\n",
       " 'HG00531',\n",
       " 'HG00533',\n",
       " 'HG00534',\n",
       " 'HG00536',\n",
       " 'HG00537',\n",
       " 'HG00542',\n",
       " 'HG00543',\n",
       " 'HG00551',\n",
       " 'HG00553',\n",
       " 'HG00554',\n",
       " 'HG00556',\n",
       " 'HG00557',\n",
       " 'HG00559',\n",
       " 'HG00560',\n",
       " 'HG00565',\n",
       " 'HG00566',\n",
       " 'HG00580',\n",
       " 'HG00581',\n",
       " 'HG00583',\n",
       " 'HG00584',\n",
       " 'HG00589',\n",
       " 'HG00590',\n",
       " 'HG00592',\n",
       " 'HG00593',\n",
       " 'HG00595',\n",
       " 'HG00596',\n",
       " 'HG00598',\n",
       " 'HG00599',\n",
       " 'HG00607',\n",
       " 'HG00608',\n",
       " 'HG00610',\n",
       " 'HG00611',\n",
       " 'HG00613',\n",
       " 'HG00614',\n",
       " 'HG00619',\n",
       " 'HG00620',\n",
       " 'HG00622',\n",
       " 'HG00623',\n",
       " 'HG00625',\n",
       " 'HG00626',\n",
       " 'HG00628',\n",
       " 'HG00629',\n",
       " 'HG00631',\n",
       " 'HG00632',\n",
       " 'HG00634',\n",
       " 'HG00637',\n",
       " 'HG00638',\n",
       " 'HG00640',\n",
       " 'HG00641',\n",
       " 'HG00650',\n",
       " 'HG00651',\n",
       " 'HG00653',\n",
       " 'HG00654',\n",
       " 'HG00656',\n",
       " 'HG00657',\n",
       " 'HG00662',\n",
       " 'HG00663',\n",
       " 'HG00671',\n",
       " 'HG00672',\n",
       " 'HG00674',\n",
       " 'HG00675',\n",
       " 'HG00683',\n",
       " 'HG00684',\n",
       " 'HG00689',\n",
       " 'HG00690',\n",
       " 'HG00692',\n",
       " 'HG00693',\n",
       " 'HG00698',\n",
       " 'HG00699',\n",
       " 'HG00701',\n",
       " 'HG00704',\n",
       " 'HG00705',\n",
       " 'HG00707',\n",
       " 'HG00708',\n",
       " 'HG00717',\n",
       " 'HG00728',\n",
       " 'HG00729',\n",
       " 'HG00731',\n",
       " 'HG00732',\n",
       " 'HG00734',\n",
       " 'HG00736',\n",
       " 'HG00737',\n",
       " 'HG00739',\n",
       " 'HG00740',\n",
       " 'HG00742',\n",
       " 'HG00743',\n",
       " 'HG00759',\n",
       " 'HG00766',\n",
       " 'HG00844',\n",
       " 'HG00851',\n",
       " 'HG00864',\n",
       " 'HG00867',\n",
       " 'HG00879',\n",
       " 'HG00881',\n",
       " 'HG00956',\n",
       " 'HG00978',\n",
       " 'HG00982',\n",
       " 'HG01028',\n",
       " 'HG01029',\n",
       " 'HG01031',\n",
       " 'HG01046',\n",
       " 'HG01047',\n",
       " 'HG01048',\n",
       " 'HG01049',\n",
       " 'HG01051',\n",
       " 'HG01052',\n",
       " 'HG01054',\n",
       " 'HG01055',\n",
       " 'HG01058',\n",
       " 'HG01060',\n",
       " 'HG01061',\n",
       " 'HG01063',\n",
       " 'HG01064',\n",
       " 'HG01066',\n",
       " 'HG01067',\n",
       " 'HG01069',\n",
       " 'HG01070',\n",
       " 'HG01072',\n",
       " 'HG01073',\n",
       " 'HG01075',\n",
       " 'HG01077',\n",
       " 'HG01079',\n",
       " 'HG01080',\n",
       " 'HG01082',\n",
       " 'HG01083',\n",
       " 'HG01085',\n",
       " 'HG01086',\n",
       " 'HG01088',\n",
       " 'HG01089',\n",
       " 'HG01092',\n",
       " 'HG01094',\n",
       " 'HG01095',\n",
       " 'HG01097',\n",
       " 'HG01098',\n",
       " 'HG01101',\n",
       " 'HG01102',\n",
       " 'HG01104',\n",
       " 'HG01105',\n",
       " 'HG01107',\n",
       " 'HG01108',\n",
       " 'HG01110',\n",
       " 'HG01111',\n",
       " 'HG01112',\n",
       " 'HG01113',\n",
       " 'HG01119',\n",
       " 'HG01121',\n",
       " 'HG01122',\n",
       " 'HG01124',\n",
       " 'HG01125',\n",
       " 'HG01130',\n",
       " 'HG01131',\n",
       " 'HG01133',\n",
       " 'HG01134',\n",
       " 'HG01136',\n",
       " 'HG01137',\n",
       " 'HG01139',\n",
       " 'HG01140',\n",
       " 'HG01142',\n",
       " 'HG01148',\n",
       " 'HG01149',\n",
       " 'HG01161',\n",
       " 'HG01162',\n",
       " 'HG01164',\n",
       " 'HG01167',\n",
       " 'HG01168',\n",
       " 'HG01170',\n",
       " 'HG01171',\n",
       " 'HG01173',\n",
       " 'HG01174',\n",
       " 'HG01176',\n",
       " 'HG01177',\n",
       " 'HG01182',\n",
       " 'HG01183',\n",
       " 'HG01187',\n",
       " 'HG01188',\n",
       " 'HG01190',\n",
       " 'HG01191',\n",
       " 'HG01197',\n",
       " 'HG01198',\n",
       " 'HG01200',\n",
       " 'HG01204',\n",
       " 'HG01205',\n",
       " 'HG01241',\n",
       " 'HG01242',\n",
       " 'HG01247',\n",
       " 'HG01248',\n",
       " 'HG01250',\n",
       " 'HG01251',\n",
       " 'HG01253',\n",
       " 'HG01254',\n",
       " 'HG01256',\n",
       " 'HG01257',\n",
       " 'HG01259',\n",
       " 'HG01260',\n",
       " 'HG01269',\n",
       " 'HG01271',\n",
       " 'HG01272',\n",
       " 'HG01275',\n",
       " 'HG01277',\n",
       " 'HG01280',\n",
       " 'HG01281',\n",
       " 'HG01284',\n",
       " 'HG01286',\n",
       " 'HG01302',\n",
       " 'HG01303',\n",
       " 'HG01305',\n",
       " 'HG01308',\n",
       " 'HG01311',\n",
       " 'HG01312',\n",
       " 'HG01323',\n",
       " 'HG01325',\n",
       " 'HG01326',\n",
       " 'HG01334',\n",
       " 'HG01341',\n",
       " 'HG01342',\n",
       " 'HG01344',\n",
       " 'HG01345',\n",
       " 'HG01348',\n",
       " 'HG01350',\n",
       " 'HG01351',\n",
       " 'HG01353',\n",
       " 'HG01354',\n",
       " 'HG01356',\n",
       " 'HG01357',\n",
       " 'HG01359',\n",
       " 'HG01360',\n",
       " 'HG01362',\n",
       " 'HG01363',\n",
       " 'HG01365',\n",
       " 'HG01366',\n",
       " 'HG01369',\n",
       " 'HG01372',\n",
       " 'HG01374',\n",
       " 'HG01375',\n",
       " 'HG01377',\n",
       " 'HG01378',\n",
       " 'HG01383',\n",
       " 'HG01384',\n",
       " 'HG01389',\n",
       " 'HG01390',\n",
       " 'HG01392',\n",
       " 'HG01393',\n",
       " 'HG01395',\n",
       " 'HG01396',\n",
       " 'HG01398',\n",
       " 'HG01402',\n",
       " 'HG01403',\n",
       " 'HG01405',\n",
       " 'HG01412',\n",
       " 'HG01413',\n",
       " 'HG01414',\n",
       " 'HG01431',\n",
       " 'HG01432',\n",
       " 'HG01435',\n",
       " 'HG01437',\n",
       " 'HG01438',\n",
       " 'HG01440',\n",
       " 'HG01441',\n",
       " 'HG01443',\n",
       " 'HG01444',\n",
       " 'HG01447',\n",
       " 'HG01455',\n",
       " 'HG01456',\n",
       " 'HG01459',\n",
       " 'HG01461',\n",
       " 'HG01462',\n",
       " 'HG01464',\n",
       " 'HG01465',\n",
       " 'HG01468',\n",
       " 'HG01474',\n",
       " 'HG01479',\n",
       " 'HG01485',\n",
       " 'HG01486',\n",
       " 'HG01488',\n",
       " 'HG01489',\n",
       " 'HG01491',\n",
       " 'HG01492',\n",
       " 'HG01494',\n",
       " 'HG01495',\n",
       " 'HG01497']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "ds.samples()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tiledbvcf store -u s3://genomic-datasets/notebooks/1kgp3/1kg-array \\\n",
    "    --threads 16 \\\n",
    "    --sample-batch-size 20 \\\n",
    "    --verbose \\\n",
    "    --stats \\\n",
    "    data/filtered-bcfs/*.bcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running with `--verbose` you will get a summary printed at the end: `Done. Ingested 857,389,804 records (+ 4,076,523 anchors) from 2,504 samples in 2,133.21 seconds.`\n",
    "\n",
    "This indicates we’ve ingested over 857 million genomic positions into the TileDB-VCF dataset. With an `m5.4xlarge` instance costing \\$0.768 an hour, and this ingestion took just under 40 minutes, the cost of ingestion was \\$0.50 USD, so ingesting all data from the 1KG Phase results would cost roughly $7.00.\n",
    "\n",
    "The final array is 6Gb, or just under half the size of the individual compressed BCF files.\n",
    "\n",
    "Following ingestion, it may help performance to consolidate the metadata fragments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tiledbvcf utils consolidate fragment_meta -u s3://genomic-datasets/notebooks/1kgp3/1kg-array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading, Analysis and Exporting\n",
    "\n",
    "In this section we will walk through accessing the TileDB-VCF dataset with python and also exporting back to VCF and TSV.\n",
    "\n",
    "### Python API\n",
    "\n",
    "TileDB-VCF offers several APIs, for this section we will focus on the Python API. First we load the module and setup a few variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiledbvcf\n",
    "\n",
    "uri = \"s3://genomic-datasets/notebooks/1kgp3/1kg-array\"\n",
    "bedfile = \"s3://genomic-datasets/notebooks/1kgp3/hg37_chr1_covidHgiGwasR4PvalC2_plog3.bed.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading into Pandas Dataframe\n",
    "\n",
    "Pandas is one of the most popular data science tools in python. TileDB VCF’s python API produces results directly into a pandas dataframe. This makes its easy to analyze the data and leverage any of pandas’ builtin algorithms.\n",
    "\n",
    "Let’s run a typical query on the 1kg TileDB-VCF dataset we created above. We’ll retrieve all variants that overlap the gene *MTOR* on chr 1 for sample HG00096, along with a few attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>alleles</th>\n",
       "      <th>fmt_GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43337897</td>\n",
       "      <td>43337897</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43339092</td>\n",
       "      <td>43339092</td>\n",
       "      <td>[C, T]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43339203</td>\n",
       "      <td>43339203</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43340776</td>\n",
       "      <td>43340776</td>\n",
       "      <td>[T, C]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43340779</td>\n",
       "      <td>43340779</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43341662</td>\n",
       "      <td>43341662</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43342021</td>\n",
       "      <td>43342021</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43343390</td>\n",
       "      <td>43343390</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43344193</td>\n",
       "      <td>43344193</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43344632</td>\n",
       "      <td>43344632</td>\n",
       "      <td>[T, A]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43346551</td>\n",
       "      <td>43346551</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43347556</td>\n",
       "      <td>43347556</td>\n",
       "      <td>[C, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43347925</td>\n",
       "      <td>43347925</td>\n",
       "      <td>[C, T]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43348081</td>\n",
       "      <td>43348081</td>\n",
       "      <td>[G, T]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43348184</td>\n",
       "      <td>43348184</td>\n",
       "      <td>[A, T]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43350603</td>\n",
       "      <td>43350603</td>\n",
       "      <td>[C, T]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43351984</td>\n",
       "      <td>43351984</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>43352685</td>\n",
       "      <td>43352685</td>\n",
       "      <td>[A, G]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_name contig  pos_start   pos_end alleles  fmt_GT\n",
       "0      HG00096      1   43337897  43337897  [A, G]  [1, 0]\n",
       "1      HG00096      1   43339092  43339092  [C, T]  [1, 1]\n",
       "2      HG00096      1   43339203  43339203  [G, A]  [1, 1]\n",
       "3      HG00096      1   43340776  43340776  [T, C]  [1, 1]\n",
       "4      HG00096      1   43340779  43340779  [A, G]  [1, 1]\n",
       "5      HG00096      1   43341662  43341662  [A, G]  [1, 1]\n",
       "6      HG00096      1   43342021  43342021  [G, A]  [1, 0]\n",
       "7      HG00096      1   43343390  43343390  [A, G]  [1, 1]\n",
       "8      HG00096      1   43344193  43344193  [G, A]  [1, 1]\n",
       "9      HG00096      1   43344632  43344632  [T, A]  [1, 1]\n",
       "10     HG00096      1   43346551  43346551  [A, G]  [1, 1]\n",
       "11     HG00096      1   43347556  43347556  [C, G]  [1, 1]\n",
       "12     HG00096      1   43347925  43347925  [C, T]  [1, 1]\n",
       "13     HG00096      1   43348081  43348081  [G, T]  [1, 1]\n",
       "14     HG00096      1   43348184  43348184  [A, T]  [1, 1]\n",
       "15     HG00096      1   43350603  43350603  [C, T]  [1, 1]\n",
       "16     HG00096      1   43351984  43351984  [A, G]  [1, 1]\n",
       "17     HG00096      1   43352685  43352685  [A, G]  [1, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = tiledbvcf.ReadConfig(memory_budget_mb=8192)\n",
    "\n",
    "ds = tiledbvcf.Dataset(uri, stats = True, cfg = cfg)\n",
    "\n",
    "ds.read(\n",
    "    attrs = [\"sample_name\", \"contig\", \"pos_start\", \"pos_end\", \"alleles\", \"fmt_GT\"], \n",
    "    regions = [\"1:43337848-43352772\"],\n",
    "    samples = [\"HG00096\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `Dataset` object was created with `stats = True` you can print out a variety of useful information about the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== READ ====\n",
      "\n",
      "- Number of read queries: 3\n",
      "- Number of attempts until results are found: 3\n",
      "\n",
      "- Number of attributes read: 5\n",
      "  * Number of fixed-sized attributes read: 2\n",
      "  * Number of var-sized attributes read: 3\n",
      "- Number of dimensions read: 5\n",
      "  * Number of fixed-sized dimensions read: 1\n",
      "  * Number of var-sized dimensions read: 4\n",
      "\n",
      "- Number of logical tiles overlapping the query: 128\n",
      "- Number of physical tiles read: 2176\n",
      "  * Number of physical fixed-sized tiles read: 384\n",
      "  * Number of physical var-sized tiles read: 1792\n",
      "- Number of cells read: 12524\n",
      "- Number of result cells: 2524\n",
      "- Percentage of useful cells read: 20.1533%\n",
      "\n",
      "- Number of bytes read: 316500 bytes (0.000294764 GB) \n",
      "- Number of read operations: 2728\n",
      "- Number of bytes unfiltered: 1404653 bytes (0.00130819 GB) \n",
      "- Unfiltering inflation factor: 4.43808x\n",
      "\n",
      "- Time to compute estimated result size: 0.226271 secs\n",
      "  * Time to compute tile overlap: 0.296438 secs\n",
      "    > Time to compute relevant fragments: 0.000684499 secs\n",
      "    > Time to load relevant fragment R-trees: 0.292355 secs\n",
      "    > Time to compute relevant fragment tile overlap: 0.00334145 secs\n",
      "\n",
      "- Time to open array: 1.47771 secs\n",
      "  * Time to load array schema: 0.0642025 secs\n",
      "  * Time to load consolidated fragment metadata: 0.0381051 secs\n",
      "  * Time to load fragment metadata: 1.25327 secs\n",
      "\n",
      "- Total metadata read: 359434 bytes (0.000334749 GB) \n",
      "  * Array schema: 766 bytes (7.13393e-07 GB) \n",
      "  * Consolidated fragment metadata: 130292 bytes (0.000121344 GB) \n",
      "  * Fragment metadata: 96012 bytes (8.94181e-05 GB) \n",
      "  * R-tree: 46268 bytes (4.30904e-05 GB) \n",
      "  * Fixed-sized tile offsets: 38432 bytes (3.57926e-05 GB) \n",
      "  * Var-sized tile offsets: 22832 bytes (2.1264e-05 GB) \n",
      "  * Var-sized tile sizes: 24832 bytes (2.31266e-05 GB) \n",
      "\n",
      "- Time to load array metadata: 0.0971574 secs\n",
      "  * Array metadata size: 102 bytes (9.49949e-08 GB) \n",
      "\n",
      "- Time to initialize the read state: 0.0727732 secs\n",
      "\n",
      "- Read time: 0.527277 secs\n",
      "  * Time to compute next partition: 0.000906719 secs\n",
      "  * Time to compute result coordinates: 0.389981 secs\n",
      "    > Time to compute sparse result tiles: 0.0001632 secs\n",
      "    > Time to read coordinate tiles: 0.378157 secs\n",
      "    > Time to unfilter coordinate tiles: 0.00425095 secs\n",
      "    > Time to compute range result coordinates: 0.00219325 secs\n",
      "  * Time to compute sparse result cell slabs: 1.5181e-05 secs\n",
      "  * Time to copy result attribute values: 0.135654 secs\n",
      "    > Time to read attribute tiles: 0.133284 secs\n",
      "    > Time to unfilter attribute tiles: 0.00107886 secs\n",
      "    > Time to copy fixed-sized attribute values: 0.000267195 secs\n",
      "    > Time to copy var-sized attribute values: 0.000320791 secs\n",
      "  * Time to copy result coordinates: 0.000672115 secs\n",
      "    > Time to copy fixed-sized coordinates: 0.000131452 secs\n",
      "    > Time to copy var-sized coordinates: 0.000436485 secs\n",
      "\n",
      "- Total read query time (array open + init state + read): 0.60005 secs\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds.tiledb_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above query took under a second for a single sample. Running this same query across all 2,504 samples took only 8.2 secs.\n",
    "\n",
    "For production-sized queries that encompass large portions of the genome it's more convenient to provide bed files with the query regions. Here, we'll use a bed file on s3 that contains 1,040 regions on chr1 that show at least a moderate association with with SARS-CoV-2 infection susceptibility (data obtained from the [COVID-19 Host Genetics Initiative](https://www.covid19hg.org/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>alleles</th>\n",
       "      <th>info_DP</th>\n",
       "      <th>fmt_GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>2265099</td>\n",
       "      <td>2265099</td>\n",
       "      <td>[C, T]</td>\n",
       "      <td>[16479]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00099</td>\n",
       "      <td>1</td>\n",
       "      <td>2265099</td>\n",
       "      <td>2265099</td>\n",
       "      <td>[C, T]</td>\n",
       "      <td>[16479]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00107</td>\n",
       "      <td>1</td>\n",
       "      <td>2265099</td>\n",
       "      <td>2265099</td>\n",
       "      <td>[C, T]</td>\n",
       "      <td>[16479]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>2337537</td>\n",
       "      <td>2337537</td>\n",
       "      <td>[C, G]</td>\n",
       "      <td>[11721]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>2337537</td>\n",
       "      <td>2337537</td>\n",
       "      <td>[C, G]</td>\n",
       "      <td>[11721]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>HG00102</td>\n",
       "      <td>1</td>\n",
       "      <td>247999680</td>\n",
       "      <td>247999680</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[19889]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>247999680</td>\n",
       "      <td>247999680</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[19889]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>247999680</td>\n",
       "      <td>247999680</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[19889]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>HG00106</td>\n",
       "      <td>1</td>\n",
       "      <td>247999680</td>\n",
       "      <td>247999680</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[19889]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>HG00107</td>\n",
       "      <td>1</td>\n",
       "      <td>247999680</td>\n",
       "      <td>247999680</td>\n",
       "      <td>[G, A]</td>\n",
       "      <td>[19889]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_name contig  pos_start    pos_end alleles  info_DP  fmt_GT\n",
       "0        HG00097      1    2265099    2265099  [C, T]  [16479]  [0, 1]\n",
       "1        HG00099      1    2265099    2265099  [C, T]  [16479]  [0, 1]\n",
       "2        HG00107      1    2265099    2265099  [C, T]  [16479]  [1, 0]\n",
       "3        HG00096      1    2337537    2337537  [C, G]  [11721]  [1, 1]\n",
       "4        HG00097      1    2337537    2337537  [C, G]  [11721]  [1, 1]\n",
       "...          ...    ...        ...        ...     ...      ...     ...\n",
       "3470     HG00102      1  247999680  247999680  [G, A]  [19889]  [1, 1]\n",
       "3471     HG00103      1  247999680  247999680  [G, A]  [19889]  [1, 1]\n",
       "3472     HG00105      1  247999680  247999680  [G, A]  [19889]  [1, 1]\n",
       "3473     HG00106      1  247999680  247999680  [G, A]  [19889]  [1, 1]\n",
       "3474     HG00107      1  247999680  247999680  [G, A]  [19889]  [1, 1]\n",
       "\n",
       "[3475 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tiledbvcf.Dataset(uri, stats = True, cfg = cfg)\n",
    "\n",
    "df = ds.read(\n",
    "    attrs = [\"sample_name\", \"contig\", \"pos_start\", \"pos_end\", \"alleles\", \"info_DP\", \"fmt_GT\"], \n",
    "    samples = ds.samples()[:10],\n",
    "    bed_file = bedfile\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query completed in 1.9 secs for 10 samples.\n",
    "\n",
    "#### Filter Example\n",
    "\n",
    "Using the pandas dataframe returned from TileDB-VCF we can apply additional filters. For instance if we wanted to filter the above result on read depth (`info_DP`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.info_DP.apply(lambda x: x[0] > 5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python API supports a variety of advanced uses, batching, partitioning, dask and more. We are happy to follow-up with additional details beyond these initial examples.\n",
    "\n",
    "### CLI Exporting\n",
    "\n",
    "In addition to the python API it is also possible to export the dataset back into VCF format. This can be helpful in interoperating with legacy tools.\n",
    "\n",
    "#### Exporting to VCF\n",
    "\n",
    "When exporting to VCF you can specify any number of samples, and each will be exported to its own file in vcf, compressed vcf or bcf format depdning on what you set for `--output-format`.\n",
    "\n",
    "For example to export the entire sample for `HG00096`, `HG00097`, and `HG00099` you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tiledbvcf export --uri s3://genomic-datasets/notebooks/1kgp3/1kg-array \\\n",
    "    --output-format v \\\n",
    "    --sample-names HG00096,HG00097,HG00099 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces 3 files: `HG00096.vcf`, `HG00097.vcf`, and `HG00099.vcf`.\n",
    "\n",
    "##### Filtering Exports\n",
    "\n",
    "You can also combine the use of regions (bed file or list of regions passed to cli) to filter the export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tiledbvcf export --uri s3://genomic-datasets/notebooks/1kgp3/1kg3-array \\\n",
    "    --output-format v \\\n",
    "    --sample-names HG00096,HG00097,HG00099 \\\n",
    "    --regions-file s3://genomic-datasets/notebooks/1kgp3/hg37_chr1_covidHgiGwasR4PvalC2_plog3.bed.gz \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will also produce the 3 VCF files, like the previous export. However, these files are filtered for the same SARS-CoV-2 associated genomic regions specified in the bed file.\n",
    "\n",
    "\n",
    "#### Exporting to TSV\n",
    "\n",
    "For even more generic usecases you can export data to tab seperate files with the `--output-format t` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tiledbvcf export --uri s3://genomic-datasets/notebooks/1kgp3/1kg-array \\\n",
    "    --output-format t \\\n",
    "    --tsv-fields CHR,POS,I:END,REF,ALT,S:GT,Q:POS,Q:END \\\n",
    "    --sample-names HG00096,HG00097,HG00099 \\\n",
    "    --regions-file s3://genomic-datasets/notebooks/1kgp3/hg37_chr1_covidHgiGwasR4PvalC2_plog3.bed.gz \\\n",
    "    --verbose --output-path sars-cov-2-associated-regions.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tiledbvcf-py': conda)",
   "metadata": {
    "interpreter": {
     "hash": "31ba5af413596af6738a327c8a634dbdbb4a75a541688500a2f353ca9ee62cf0"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}