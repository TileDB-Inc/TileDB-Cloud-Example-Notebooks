{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is an example of how to train a basic image classification model with Keras and Tensorflow, using TileDB as storage for images.\n",
    "First of all let's import everything we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tiledb\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have to download the flower image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] downloading image data...\n",
      "[STATUS] downloading image data finished...\n"
     ]
    }
   ],
   "source": [
    "print(\"[STATUS] downloading image data...\")\n",
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n",
    "os.system(\"mv ~/.keras/datasets/flower_photos ./data\")\n",
    "print(\"[STATUS] downloading image data finished...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's define image size in order to later rescale our images, batch size for training our model, data and TileDB array paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Image size for rescaling.\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Batch size for training an image classification model.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Where our data live.\n",
    "DATA_PATH = \"data/flower_photos\"\n",
    "\n",
    "# Where our tileDB arrays live.\n",
    "TILEDB_PATH = \"data/flower_photos_tiledb\"\n",
    "\n",
    "if not os.path.exists(TILEDB_PATH):\n",
    "    os.mkdir(TILEDB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We move on by getting class names from image data directory. We then perform basic one hot encoding for image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get labels/classes\n",
    "labels = [name for name in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, name))]\n",
    "\n",
    "# Encode labels\n",
    "labels_dict = {labels[i]: i for i in range(0, len(labels))}\n",
    "number_of_classes = len(labels)\n",
    "one_hot_encodings = np.eye(number_of_classes, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next step is to load images, perform a basic preprocessing step and store them as TileDB arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] image loading and basic preprocessing...\n",
      "[STATUS] processed folder: roses\n",
      "[STATUS] processed folder: sunflowers\n",
      "[STATUS] processed folder: daisy\n",
      "[STATUS] processed folder: dandelion\n",
      "[STATUS] processed folder: tulips\n",
      "[STATUS] completed image resizing...\n"
     ]
    }
   ],
   "source": [
    "# Empty lists to hold images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "print(\"[STATUS] image loading and basic preprocessing...\")\n",
    "\n",
    "# loop over the training data sub-folders\n",
    "for current_label in labels_dict:\n",
    "\n",
    "    class_image_paths = glob.glob(DATA_PATH + \"/\" + current_label + \"/*.jpg\")\n",
    "\n",
    "    # loop over the images per class\n",
    "    for image_path in class_image_paths:\n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "        # Here is where you may add any kind of image preprocessing you need.\n",
    "\n",
    "        # update the list of images\n",
    "        images.append(image.astype(np.float32))\n",
    "\n",
    "        # update the list of labels\n",
    "        labels.append(one_hot_encodings[labels_dict[current_label]])\n",
    "\n",
    "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
    "\n",
    "# Create two numpy arrays with all images and all labels respectively.\n",
    "images = np.stack(images, axis=0)\n",
    "labels = np.stack(labels, axis=0)\n",
    "\n",
    "print(\"[STATUS] completed image resizing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now split our dataset in train, validate and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] train images array shape (2936, 224, 224, 3)\n",
      "[STATUS] validate images array shape (734, 224, 224, 3)\n",
      "[STATUS] train labels array shape (2936, 5)\n",
      "[STATUS] validate labels array shape (734, 5)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle image and label data in the same manner\n",
    "randomize = np.arange(images.shape[0])\n",
    "np.random.shuffle(randomize)\n",
    "images = images[randomize]\n",
    "labels = labels[randomize]\n",
    "\n",
    "train_max_indx = int(labels.shape[0] * 0.8)\n",
    "\n",
    "train_images = images[:train_max_indx]\n",
    "train_labels = labels[:train_max_indx]\n",
    "\n",
    "validate_images = images[train_max_indx:]\n",
    "validate_labels = labels[train_max_indx:]\n",
    "\n",
    "# get the overall image dataset shapes\n",
    "print(\"[STATUS] train images array shape {}\".format(train_images.shape))\n",
    "print(\"[STATUS] validate images array shape {}\".format(validate_images.shape))\n",
    "\n",
    "# get the overall label dataset shapes\n",
    "print(\"[STATUS] train labels array shape {}\".format(train_labels.shape))\n",
    "print(\"[STATUS] validate labels array shape {}\".format(validate_labels.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now is the time to store image data and labels to TileDB arrays. We have to define the schema, dimensions and tile extend.\n",
    "We will use 3 dimensions for images, i.e, 1st dimension will be the image id, while the 2nd and 3rd dimensions correspond to each\n",
    "image's x-axis and y-axis. RGB values will be stored as attributes in each TileDB array cell. Because of the fact that during\n",
    "training a model we will load image batches equal to the BATCH_SIZE, tile extend of the image_id dimension should be equal\n",
    "with the BATCH_SIZE. The tile extend of the other two dimensions should be equal with the image x and y size respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] images TileDB arrays are ready.\n",
      "[STATUS] labels TileDB arrays are ready.\n"
     ]
    }
   ],
   "source": [
    "# Define dimensions, Schema and write TileDB array for image data\n",
    "train_image_id = tiledb.Dim(name=\"image_id\", domain=(0, train_images.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "validate_image_id = tiledb.Dim(name=\"image_id\", domain=(0, validate_images.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "\n",
    "# The following dimensions are common\n",
    "x_axis = tiledb.Dim(name=\"x_axis\", domain=(0, train_images.shape[1] - 1), tile=train_images.shape[1], dtype=np.int32)\n",
    "y_axis = tiledb.Dim(name=\"y_axis\", domain=(0, train_images.shape[2] - 1), tile=train_images.shape[2], dtype=np.int32)\n",
    "\n",
    "# Two different schemas for train and validate\n",
    "train_images_schema = tiledb.ArraySchema(domain=tiledb.Domain(train_image_id, x_axis, y_axis),\n",
    "                                         sparse=False,\n",
    "                                         attrs=[tiledb.Attr(name=\"rgb\", dtype=[(\"\", np.float32),\n",
    "                                                                               (\"\", np.float32),\n",
    "                                                                               (\"\", np.float32)])])\n",
    "\n",
    "validate_images_schema = tiledb.ArraySchema(domain=tiledb.Domain(validate_image_id, x_axis, y_axis),\n",
    "                                            sparse=False,\n",
    "                                            attrs=[tiledb.Attr(name=\"rgb\", dtype=[(\"\", np.float32),\n",
    "                                                                                  (\"\", np.float32),\n",
    "                                                                                  (\"\", np.float32)])])\n",
    "\n",
    "tiledb.Array.create(TILEDB_PATH + \"/train_image_array\", train_images_schema)\n",
    "tiledb.Array.create(TILEDB_PATH + \"/validate_image_array\", validate_images_schema)\n",
    "\n",
    "train_image_view = train_images.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "validate_image_view = validate_images.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/train_image_array\", 'w') as train_images_tiledb:\n",
    "    train_images_tiledb[:] = train_image_view\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/validate_image_array\", 'w') as validate_images_tiledb:\n",
    "    validate_images_tiledb[:] = validate_image_view\n",
    "\n",
    "print(\"[STATUS] images TileDB arrays are ready.\")\n",
    "\n",
    "# Similarly for label arrays.\n",
    "train_label_id = tiledb.Dim(name=\"label_id\", domain=(0, train_labels.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "validate_label_id = tiledb.Dim(name=\"label_id\", domain=(0, validate_labels.shape[0] - 1), tile=BATCH_SIZE, dtype=np.int32)\n",
    "\n",
    "train_labels_schema = tiledb.ArraySchema(domain=tiledb.Domain(train_label_id),\n",
    "                                         sparse=False,\n",
    "                                         attrs=[tiledb.Attr(name=\"label\",\n",
    "                                                            dtype=[(\"\", np.float32),\n",
    "                                                                   (\"\", np.float32),\n",
    "                                                                   (\"\", np.float32),\n",
    "                                                                   (\"\", np.float32),\n",
    "                                                                   (\"\", np.float32)])])\n",
    "\n",
    "validate_labels_schema = tiledb.ArraySchema(domain=tiledb.Domain(validate_label_id),\n",
    "                                            sparse=False,\n",
    "                                            attrs=[tiledb.Attr(name=\"label\",\n",
    "                                                               dtype=[(\"\", np.float32),\n",
    "                                                                      (\"\", np.float32),\n",
    "                                                                      (\"\", np.float32),\n",
    "                                                                      (\"\", np.float32),\n",
    "                                                                      (\"\", np.float32)])])\n",
    "\n",
    "\n",
    "tiledb.Array.create(TILEDB_PATH + \"/train_label_array\", train_labels_schema)\n",
    "tiledb.Array.create(TILEDB_PATH + \"/validate_label_array\", validate_labels_schema)\n",
    "\n",
    "train_labels_view = train_labels.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "validate_labels_view = validate_labels.view([(\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32), (\"\", np.float32)])\n",
    "\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/train_label_array\", 'w') as train_labels_tiledb:\n",
    "    train_labels_tiledb[:] = train_labels_view\n",
    "\n",
    "with tiledb.open(TILEDB_PATH + \"/validate_label_array\", 'w') as validate_labels_tiledb:\n",
    "    validate_labels_tiledb[:] = validate_labels_view\n",
    "\n",
    "print(\"[STATUS] labels TileDB arrays are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will need a data generator than will feed training and validation data into the model while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generator(tiledb_images_obj, tiledb_labels_obj, shape, batch_size=32):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "\n",
    "        # Get index to start each batch\n",
    "        for offset in range(0, shape, batch_size):\n",
    "\n",
    "            # Get the samples you'll use in this batch. We have to convert structured numpy arrays to\n",
    "            # numpy arrays.\n",
    "\n",
    "            # Avoid reshaping error in last batch\n",
    "            if offset + batch_size > shape:\n",
    "                batch_size = shape - offset\n",
    "\n",
    "            x_train = tiledb_images_obj[offset:offset + batch_size]['rgb'].\\\n",
    "                view(np.float32).reshape(batch_size, IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "\n",
    "            y_train = tiledb_labels_obj[offset:offset + batch_size]['label'].\\\n",
    "                view(np.float32).reshape(batch_size, number_of_classes)\n",
    "\n",
    "            # The generator-y part: yield the next training batch\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will create generators for train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open TileDB image and label arrays.\n",
    "train_images_tiledb = tiledb.open(TILEDB_PATH + \"/train_image_array\")\n",
    "train_labels_tiledb = tiledb.open(TILEDB_PATH + \"/train_label_array\")\n",
    "\n",
    "validate_images_tiledb = tiledb.open(TILEDB_PATH + \"/validate_image_array\")\n",
    "validate_labels_tiledb = tiledb.open(TILEDB_PATH + \"/validate_label_array\")\n",
    "\n",
    "# Create generators\n",
    "train_generator = generator(tiledb_images_obj=train_images_tiledb,\n",
    "                            tiledb_labels_obj=train_labels_tiledb,\n",
    "                            shape=train_images.shape[0],\n",
    "                            batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "validate_generator = generator(tiledb_images_obj=validate_images_tiledb,\n",
    "                               tiledb_labels_obj=validate_labels_tiledb,\n",
    "                               shape=validate_images.shape[0],\n",
    "                               batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now define a function that creates an image classification model using Keras with Tensorflow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_of_classes):\n",
    "\n",
    "    input_shape = input_shape\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, name='conv2d_1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_1'))\n",
    "    model.add(Conv2D(32, (3, 3), name='conv2d_2'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_of_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed by creating a model with the corresponding checkpoint and early stopping callbacks and train it by passing\n",
    "train and validation generators as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "maxpool2d_1 (MaxPooling2D)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "maxpool2d_2 (MaxPooling2D)   (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 96800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                6195264   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 6,205,733\n",
      "Trainable params: 6,205,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-18-2c6a4fa37d3a>:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "91/91 [==============================] - 52s 569ms/step - loss: 27.5401 - accuracy: 0.2194 - val_loss: 1.6072 - val_accuracy: 0.2614\n",
      "Epoch 2/5\n",
      "41/91 [============>.................] - ETA: 21s - loss: 1.6050 - accuracy: 0.2724"
     ]
    }
   ],
   "source": [
    "model = create_model(input_shape=images[0].shape, num_of_classes=number_of_classes)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"./data/flower_model.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_images.shape[0] // BATCH_SIZE,\n",
    "        epochs=5,\n",
    "        validation_data=validate_generator,\n",
    "        validation_steps=validate_images.shape[0] // BATCH_SIZE,\n",
    "        callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}